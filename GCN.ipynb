{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample shape: torch.Size([1, 6885]), label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blastaistudent/miniconda3/envs/ld/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 6885]) torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, audio_dir, visual_dir, split_file, annotation_file):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.visual_dir = visual_dir\n",
    "\n",
    "        # Load file IDs from split file\n",
    "        with open(split_file, 'r') as f:\n",
    "            fids = f.read().splitlines()\n",
    "\n",
    "        # Generate paths to audio and visual files\n",
    "        self.audio_files = [os.path.join(audio_dir, f\"{i}.npy\") for i in fids]\n",
    "        self.visual_files = [os.path.join(visual_dir, f\"{i}.npy\") for i in fids]\n",
    "\n",
    "        # Generate labels from file IDs\n",
    "        self.labels = [1 if 'lie' in fid.lower() else 0 for fid in fids]\n",
    "\n",
    "        # Load annotations\n",
    "        self.annotations = pd.read_csv(annotation_file, index_col=0)\n",
    "        missing_fids = [fid.split('/')[-1] for fid in fids if fid not in self.annotations.index]\n",
    "        if missing_fids:\n",
    "            raise ValueError(f\"Missing file ids in annotation file: {missing_fids}\")\n",
    "        self.annotations = self.annotations.loc[fids].values\n",
    "\n",
    "        # Ensure that files exist\n",
    "        for i in self.audio_files:\n",
    "            if not os.path.exists(i):\n",
    "                raise FileNotFoundError(f\"File not found: {i}\")\n",
    "        for i in self.visual_files:\n",
    "            if not os.path.exists(i):\n",
    "                raise FileNotFoundError(f\"File not found: {i}\")\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load audio and visual features\n",
    "        audio_features = np.load(self.audio_files[idx])\n",
    "        visual_features = np.load(self.visual_files[idx])\n",
    "        \n",
    "        # Ensure the same length for both modalities\n",
    "        min_length = min(audio_features.shape[0], visual_features.shape[0])\n",
    "        audio_features = audio_features[:min_length]\n",
    "        visual_features = visual_features[:min_length]\n",
    "\n",
    "        # Get annotations for this sample\n",
    "        annotation = self.annotations[idx]\n",
    "        annotation_repeated = np.tile(annotation, (min_length, 1))\n",
    "\n",
    "        # Concatenate audio, visual features, and annotations along the last dimension\n",
    "        concat_data = audio_features\n",
    "        #np.concatenate([audio_features, visual_features], axis=-1)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        concat_data = torch.tensor(concat_data, dtype=torch.float32)\n",
    "        \n",
    "        # Get the label for this sample\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return concat_data, label\n",
    "        \n",
    "    def __len__(self):\n",
    "            return len(self.audio_files)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    \n",
    "    # Determine the max length of the sequences\n",
    "    max_len = max([i.shape[0] for i in data])\n",
    "    \n",
    "    # Pad sequences to the max length\n",
    "    padded_batch = [torch.nn.functional.pad(i, (0, 0, 0, max_len - i.shape[0])) for i in data]\n",
    "    \n",
    "    # Stack into a tensor\n",
    "    data = torch.stack(padded_batch)\n",
    "    \n",
    "    # Stack labels into a tensor\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Example usage\n",
    "audio_dir = \"/data/lie_detection/clips_umich/opensmile_extraction\"\n",
    "visual_dir = \"/data/lie_detection/clips_umich/viT_50hz\"\n",
    "split_file = \"/data/lie_detection/clips_umich/train.txt\"\n",
    "annotation_file = \"/home/blastaistudent/proj-lie-detection/annotation_id_as_index.csv\"\n",
    "\n",
    "dataset = MultiModalDataset(audio_dir, visual_dir, split_file, annotation_file)\n",
    "print(f\"dataset sample shape: {dataset[0][0].shape}, label: {dataset[0][1]}\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=12, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "print(batch[0].shape, batch[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5671,  0.3718,  0.0000,  ...,  0.0892,  0.2583, -0.0228])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blastaistudent/miniconda3/envs/ld/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "batch_size=12\n",
    "val_split=\"/data/lie_detection/clips_umich/val.txt\"\n",
    "valset = MultiModalDataset(audio_dir, visual_dir, val_split,annotation_file)\n",
    "valloader = DataLoader(valset, batch_size, shuffle=False, num_workers=2, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blastaistudent/miniconda3/envs/ld/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_split = \"/data/lie_detection/clips_umich/test.txt\"\n",
    "testset = MultiModalDataset(audio_dir, visual_dir, test_split, annotation_file)\n",
    "testloader = DataLoader(testset, batch_size, shuffle=False, num_workers=2, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "\n",
    "X =[]\n",
    "y =  dataloader.dataset.labels\n",
    "\n",
    "# Concatenate all the features and labels into single tensors\n",
    "for i in range(len(dataloader.dataset)):\n",
    "    X.append(dataloader.dataset[i][0])\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/tmp/ipykernel_1140490/2086615131.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(X[i], dtype=torch.float)\n",
      "/home/blastaistudent/miniconda3/envs/ld/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def numpy_to_data(X, y, k=5):\n",
    "    data_list = []\n",
    "    for i in range(len(X)):\n",
    "        x = torch.tensor(X[i], dtype=torch.float)\n",
    "        \n",
    "        k_neighbors = 1\n",
    "        \n",
    "        # Generate k-nearest neighbor graph\n",
    "        adj_matrix = kneighbors_graph(X[i], k_neighbors, mode='connectivity', include_self=True)\n",
    "        edge_index = torch.tensor(np.array(adj_matrix.nonzero()), dtype=torch.long)\n",
    "        \n",
    "        label = torch.tensor(y[i], dtype=torch.long)\n",
    "        data = Data(x=x, edge_index=edge_index, y=label.unsqueeze(0))\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "train_data = numpy_to_data(X_train, y_train, k=5)\n",
    "test_data = numpy_to_data(X_test, y_test, k=5)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "class ComplexGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, k_neighbors, dropout=0.5):\n",
    "        super(ComplexGCN, self).__init__()\n",
    "        self.k = k_neighbors\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc1 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.tanh(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 50.0000, Test Accuracy: 0.5385\n",
      "Epoch 2/40, Loss: 53.4483, Test Accuracy: 0.5385\n",
      "Epoch 3/40, Loss: 48.2759, Test Accuracy: 0.5385\n",
      "Epoch 4/40, Loss: 48.2759, Test Accuracy: 0.5385\n",
      "Epoch 5/40, Loss: 51.7241, Test Accuracy: 0.5385\n",
      "Epoch 6/40, Loss: 55.1724, Test Accuracy: 0.5385\n",
      "Epoch 7/40, Loss: 56.8966, Test Accuracy: 0.5385\n",
      "Epoch 8/40, Loss: 50.0000, Test Accuracy: 0.5385\n",
      "Epoch 9/40, Loss: 53.4483, Test Accuracy: 0.5385\n",
      "Epoch 10/40, Loss: 50.0000, Test Accuracy: 0.5385\n",
      "Epoch 11/40, Loss: 51.7241, Test Accuracy: 0.5385\n",
      "Epoch 12/40, Loss: 51.7241, Test Accuracy: 0.5385\n",
      "Epoch 13/40, Loss: 50.0000, Test Accuracy: 0.5385\n",
      "Epoch 14/40, Loss: 55.1724, Test Accuracy: 0.5385\n",
      "Epoch 15/40, Loss: 51.7241, Test Accuracy: 0.5385\n",
      "Epoch 16/40, Loss: 46.5517, Test Accuracy: 0.5385\n",
      "Epoch 17/40, Loss: 48.2759, Test Accuracy: 0.5385\n",
      "Epoch 18/40, Loss: 51.7241, Test Accuracy: 0.5385\n",
      "Epoch 19/40, Loss: 48.2759, Test Accuracy: 0.5385\n",
      "Epoch 20/40, Loss: 44.8276, Test Accuracy: 0.5385\n",
      "Epoch 21/40, Loss: 44.8276, Test Accuracy: 0.5385\n",
      "Epoch 22/40, Loss: 56.8966, Test Accuracy: 0.5385\n",
      "Epoch 23/40, Loss: 48.2759, Test Accuracy: 0.5385\n",
      "Epoch 24/40, Loss: 51.7241, Test Accuracy: 0.5385\n",
      "Epoch 25/40, Loss: 53.4483, Test Accuracy: 0.5385\n",
      "Epoch 26/40, Loss: 46.5517, Test Accuracy: 0.5385\n",
      "Epoch 27/40, Loss: 51.7241, Test Accuracy: 0.5385\n",
      "Epoch 28/40, Loss: 53.4483, Test Accuracy: 0.5385\n",
      "Epoch 29/40, Loss: 55.1724, Test Accuracy: 0.5385\n",
      "Epoch 30/40, Loss: 55.1724, Test Accuracy: 0.5385\n",
      "Epoch 31/40, Loss: 50.0000, Test Accuracy: 0.5385\n",
      "Epoch 32/40, Loss: 53.4483, Test Accuracy: 0.5385\n",
      "Epoch 33/40, Loss: 55.1724, Test Accuracy: 0.5385\n",
      "Epoch 34/40, Loss: 43.1034, Test Accuracy: 0.5385\n",
      "Epoch 35/40, Loss: 50.0000, Test Accuracy: 0.5385\n",
      "Epoch 36/40, Loss: 48.2759, Test Accuracy: 0.5385\n",
      "Epoch 37/40, Loss: 55.1724, Test Accuracy: 0.5385\n",
      "Epoch 38/40, Loss: 55.1724, Test Accuracy: 0.5385\n",
      "Epoch 39/40, Loss: 48.2759, Test Accuracy: 0.5385\n",
      "Epoch 40/40, Loss: 51.7241, Test Accuracy: 0.5385\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        14\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.54        26\n",
      "   macro avg       0.27      0.50      0.35        26\n",
      "weighted avg       0.29      0.54      0.38        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\n",
    "\n",
    "in_channels = 6885  # Number of input features per node\n",
    "hidden_channels = 64\n",
    "out_channels = 1  # Binary classification\n",
    "k_neighbors = 5\n",
    "\n",
    "model = ComplexGCN(in_channels, hidden_channels, out_channels, k_neighbors)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out.squeeze(), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for data in loader:\n",
    "        out = model(data)\n",
    "        pred = out.squeeze().round()\n",
    "        y_true.extend(data.y.cpu().detach().numpy())\n",
    "        y_pred.extend(pred.cpu().detach().numpy())\n",
    "        correct += pred.eq(data.y.float()).sum().item()\n",
    "    \n",
    "    return correct / len(loader.dataset), y_true, y_pred\n",
    "\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader)\n",
    "    test_acc, y_true, y_pred = evaluate(model, test_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# After training loop, generate the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
