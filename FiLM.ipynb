{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#github FiLM architecture base\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "def conv(ic, oc, k, s, p):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ic, oc, k, s, p),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.BatchNorm2d(oc),\n",
    "    )\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # conv(3, 128, 5, 1, 2),\n",
    "            # conv(128, 128, 3, 1, 1),\n",
    "            # conv(128, 128, 4, 2, 1),\n",
    "            # conv(128, 128, 4, 2, 1),\n",
    "            # conv(128, 128, 4, 2, 1),\n",
    "            conv(3, 128, 5, 2, 2),\n",
    "            conv(128, 128, 3, 2, 1),\n",
    "            conv(128, 128, 3, 2, 1),\n",
    "            conv(128, 128, 3, 1, 1),\n",
    "            conv(128, 128, 3, 1, 1),\n",
    "            # conv(3, 128, 4, 2, 2),\n",
    "            # conv(128, 128, 4, 2, 1),\n",
    "            # conv(128, 128, 4, 2, 1),\n",
    "            # conv(128, 128, 4, 2, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "        \n",
    "class FiLMBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FiLMBlock, self).__init__()\n",
    "        \n",
    "    def forward(self, x, gamma, beta):\n",
    "        beta = beta.view(x.size(0), x.size(1), 1, 1)\n",
    "        gamma = gamma.view(x.size(0), x.size(1), 1, 1)\n",
    "        \n",
    "        x = gamma * x + beta\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_place, out_place):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_place, out_place, 1, 1, 0)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_place, out_place, 3, 1, 1)\n",
    "        self.norm2 = nn.BatchNorm2d(out_place)\n",
    "        self.film = FiLMBlock()\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x, beta, gamma):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.film(x, beta, gamma)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = x + identity\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, prev_channels, n_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(prev_channels, 512, 1, 1, 0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.model = nn.Sequential(nn.Linear(512, 1024),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(1024, 1024),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(1024, n_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        feature = x\n",
    "        x = self.global_max_pool(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x, feature\n",
    "        \n",
    "        \n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, n_res_blocks, n_classes, n_channels):\n",
    "        super(FiLM, self).__init__()\n",
    "        \n",
    "        dim_question = 11\n",
    "        # Linear에서 나온 결과의 절반은 beta, 절반은 gamma\n",
    "        # beta, gamma 모두 ResBlock 하나당 n_channels개씩 feed\n",
    "        self.film_generator = nn.Linear(dim_question, 2 * n_res_blocks * n_channels)\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.res_blocks = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(n_res_blocks):\n",
    "            self.res_blocks.append(ResBlock(n_channels + 2, n_channels))\n",
    "            \n",
    "        self.classifier = Classifier(n_channels, n_classes)\n",
    "    \n",
    "        self.n_res_blocks = n_res_blocks\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "    def forward(self, x, question):\n",
    "        batch_size = x.size(0)\n",
    "        if x.dim() == 5:\n",
    "            # Remove extra dimensions\n",
    "            x = x.squeeze(-1).squeeze(-1)\n",
    "        x = self.feature_extractor(x)\n",
    "        film_vector = self.film_generator(question).view(\n",
    "            batch_size, self.n_res_blocks, 2, self.n_channels)\n",
    "        \n",
    "        d = x.size(2)\n",
    "        coordinate = torch.arange(-1, 1 + 0.00001, 2 / (d-1)).cuda()\n",
    "        coordinate_x = coordinate.expand(batch_size, 1, d, d)\n",
    "        coordinate_y = coordinate.view(d, 1).expand(batch_size, 1, d, d)\n",
    "        \n",
    "        for i, res_block in enumerate(self.res_blocks):\n",
    "            beta = film_vector[:, i, 0, :]\n",
    "            gamma = film_vector[:, i, 1, :]\n",
    "            \n",
    "            x = torch.cat([x, coordinate_x, coordinate_y], 1)\n",
    "            x = res_block(x, beta, gamma)\n",
    "        \n",
    "        # feature = x\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x#, feature\n",
    "\n",
    "               \n",
    "def make_model(model_dict):\n",
    "    return FiLM(model_dict['n_res_blocks'], model_dict['n_classes'], model_dict['n_channels'])\n",
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
